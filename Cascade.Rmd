---
title: "Cascade - Noisy and xy feedback"
author: "Daniel Lill"
output:
  pdf_document:
    keep_tex: yes
---

# Load libraries and define some useful paths

```{r Libraries, results='hide', echo=FALSE, message=FALSE}
library(MRAr)
library(scales)
library(xtable)
path <- paste0(getwd(), "/")
pathout <- paste0(path, "Output/")
```

```{r Names for Fit storage of different initial Conditions}
fit_name <- "Cascade-withyx-feedback-noisy"
```


```{r Call render without overwriting any previous documents, echo=FALSE, eval=FALSE, message=FALSE}
mytime <- format(Sys.time(), "%Y%m%d-%H%M")

rmarkdown::render("Cascade.Rmd", output_file = paste0(pathout, fit_name, mytime, ".pdf"))
beepr::beep("~/Promotion/Software/rimshot.mp3")
```
# Cascade

## Setup Model 
This is the setup of the ODE model.

### Prediction function
odemodel writes a C-function, which is executed in x and xs.
x is a regular prediction function while xs only finds and returns the steady states.
If the odemodel has been calculated already, it can be loaded with "load".
```{r Prediction function Cascade, results='asis'}
modelpath <- paste0(path, "Models/Cascade/")
modelname   <- "Cascade"
mymodel     <- as.eqnlist(read.csv(paste0(modelpath, modelname, ".csv")))

# myodemodel <- odemodel(mymodel, modelname = paste0(modelname), deriv = T)
# save(myodemodel, file = paste0(modelpath, "odemodel",modelname, ".RData"))
load(paste0(modelpath, "odemodel",modelname, ".RData"))

# Prediction function
x <- Xs(odemodel = myodemodel)
# Prediction function for steady states
xs <- Xs_steady(myodemodel) # When computing steady states, set deriv = F
# print(mymodel)
mymodel %>% as.eqnvec() %>% print(pander = T)
```

### Modules, their observables and the observation function
Observation function which depends also on the optimization parameters. With their help, the complexes can smoothly be switched on in the observation.

This is the naive modularization used in the Prabakaran Paper, desregarding, which species are actually the communicating ones. This is fair enough, because usually the "active" forms are consedered to be the communicating species in a non-parametric network reconstruction.
```{r Naive observation function Cascade}
modules0 <- c("x2","y2", "z2")

obs0 <- c(  "x2+a_1*Cx2y1",
            "y2+a_2*Cy2z1",
            "z2")
g <- g0 <- Y(as.eqnvec(structure(obs0, names = modules0)), mymodel, compile = TRUE, modelname = "obsfn0", attach.input = FALSE)
```

Better modularization (also, set some defaults.)
```{r good observation function Cascade}
modules1 <- c("Cx2y1","Cy2z1", "z2")

obs1 <- c("a_1*x2+Cx2y1",
         "a_2*y2+Cy2z1",
         "z2")
g1 <- Y(as.eqnvec(structure(obs1, names = modules1)), mymodel, compile = TRUE, modelname = "obsfn1", attach.input = FALSE)
```


### Parameters
Load all parameters and format them for further use.
```{r Parameters Cascade}

pars_raw <- read.csv(paste0(modelpath, "pars.csv"), header = FALSE)  # dynamical parameters
pars_raw <- structure(pars_raw$V2, names = as.character(pars_raw$V1))
ic_raw <- read.csv(paste0(modelpath, "IC.csv"), header = F)          # initial conditions
ic_raw <- structure(ic_raw$V2, names = as.character(ic_raw$V1))
# sort ics like they appear in x, so it can be used in stode()
vars_x <- attr(x, "parameters")[attr(x, "parameters") %in% names(ic_raw)]
ic_raw <- ic_raw[vars_x]

pars_opt_0 <- setdiff((g) %>% attr("parameters"),names(c(pars_raw,ic_raw)))
pars_opt_0 <- structure(rep(0, length(pars_opt_0)), names = pars_opt_0)

pars_0 <- pars <- c(ic_raw, pars_raw, pars_opt_0)


# check if all parameters are assigned a value. Both lines should evaluate to the same number.
# x_pars <- unique(union((g) %>% attr("parameters"),(xs) %>% attr("parameters")))
# names(pars) %in% x_pars %>% sum()
# x_pars %in% names(pars) %>% sum()
```


## Show the code
### Perturb modules
Now the module can be simulated to generate perturbation data.

### Parameter trafos for convenient perturbation data
Just to show the code...
Set up the perturbations
```{r  which pars are perturbed  Cascade, echo=FALSE}
# Which pars shall be perturbed?
pars_perturbed_0 <- pars_perturbed <- c("v1" = 0.8, "k4" = 0.8, "k7" = 0.8)
```

```{r define perturbation conditions Cascade, echo=FALSE}
p_pert <- p_pert_fun(pars_perturbed = pars_perturbed,
                     pars = pars_0)
```

### Perturbation data generation and elements to keep
```{r Generate perturbation data, echo=FALSE}
perturbation_prediction_0 <-  (xs*p_pert)(times = c(0,Inf), pars = pars_0, deriv = F)
r_kept_0 <- r_kept_fun(obs_fun = g0)

```

### Fitting
Just to show the code...
```{r Fit Cascade, eval=FALSE}
myfits <- mstrust(obj_alpha, center =  pars_opt_0+0.5, studyname = "Fits", cores = 3, fits = 3, sd = 0.3)
myfits %>% as.parframe() %>% plotValues()
best_fit <- myfits %>% as.parframe()
best_fit <- best_fit[abs(best_fit$a_1) < 1 & abs(best_fit$a_2) < 1, ] %>% as.parvec()
```

## Find good Parameter values to compare behaviour for different conditions
Run this chunk of code with the "plot"-line uncommented to see predictions.

A good procedure to do this, is to look at the parameters of the complex first. 
1. If kf and kr are much smaller than kcat, nothing will have a big impact. 
2. When trying to provoke an impact, these pars need to be adjusted first.
3. Then one can also look at the model equations again and of course the predictions. Try to think, which parameters are actually blocking a desired output.
4. Also think about the orders of magnitude of in- and outgoing arrows at each node.
5. Which states are at zero, which are at maximum value (ie 100)?

```{r Find good pars Cascade, eval=FALSE}
ic_list <- list(k7 = c(0.2),
                k4 = c(1),
                k31 = c(0.001),
                # k1 = 10,
                v5 = c(200),
                gainlf = c(1),
                z1=c(100),
                k10 =150
                )
pars <- pars_0
pars[names(reduce_ic_list(ic_list)[[2]])] <- reduce_ic_list(ic_list)[[2]]
ic_list <- reduce_ic_list(ic_list)[[1]]
p_ic <- p_ic_fun(ic_list)
plot((x*p_ic)(times = seq(0,1000, length.out = 50), pars))
# cat("pars: \n")
# pars
# cat("pars_0: \n")
# pars_0
# mymodel
(xs)(c(0,Inf), pars, deriv = FALSE)
```

### Plot of the different feedback strengths
This value will then be multiplied with the reaction rate k61\*y2\*z1
```{r}
# mymodel
# pars["k10"]
gain <- function(z2, gainlf, k10) (1 + gainlf*(z2/(k10 + z2)))/(1 + (z2/(k10 + z2)))
mydf <- data.frame(x=rep(1:150,5))
df <- within(mydf, {
  y <- lapply(c(0,0.1,5,10,50), function(i) gain(unique(x), i, k10 = 100)) %>% do.call(c,.) 
  color <- rep(as.character(c(0,0.1,5,10,50)), each = length(unique(x)))})
qplot(data= df, x=x,y=y, color = color, geom = "path", xlab = "z2", ylab = "Multiplicative factor") + theme_dMod() + scale_color_dMod() + guides(color=guide_legend(title = "gainlf"))

```

### Find good parameter values by fitting parameters to chosen datapoints.
```{r Parameter trafo for parameter finding}
# Parameter trafo to exclude synthesis and degradation and to set the gains to 1.

# 1. Do a logtrafo of all parameters. 
  # The logtrafos of the pars to be replaced will be omitted in the next steps
myp <- structure(paste0("exp(log", names(pars_0),")"), names = names(pars_0))

# 2. Set the parameters of syn&deg to zero
nosyndeg <- c(outer(c("ksyn", "kdeg"), c("x1","y1","z1"), FUN = paste0), 
              paste0("kdeg", c("x","y", "z"), "2"),
              c("a_1","a_2"))
nosyndeg <- structure(rep(0, length(nosyndeg)), names = nosyndeg)

# 3. Set the gains to 1 and the kinetic constants k9 and k10 to 100
gains <- c("gainuf" = 1, "gainlf" = 1, gainyf = 1, k9 = 100, k10 = 100, k11 = 100)

# 4. Incorporate these changes
myp[names(nosyndeg)] <- nosyndeg
myp[names(gains)] <- gains

# 5. Create the parameter trafo function
p_nosyndeg <- P(myp)

# 6. Create a vector of pouter. This means: apply the logtrafo to all pars except the fix ones.
  # This is not the most elegant way, since now there is a mixture of log-transformed and not log-transformed parameters, but I want the syn&deg-parameters to be exactly zero
  # Also, I add +1e-8 to the original parameters to avoid infinities when pars are originally zero.
pars_wosyndeg <- pars_0[ ! names(pars_0) %in% c(names(nosyndeg), names(gains)) ]
pouter_0 <- c(structure(log(pars_wosyndeg+1e-8), names= paste0("log", names(pars_wosyndeg))),
              nosyndeg,
              gains)
# 7. Test the parameter trafo function
# p_nosyndeg(pouter_0)

# Data generation
newsteadystate <- function(x2,cxy,y2,cyz,z2, xT=100,yT=100,zT=100) {
  newss <- c(xT-x2-cxy,
    x2,cxy,
    yT-cxy-y2-cyz,
    y2,cyz,
    zT-cyz-z2, 
    z2)
  if(any(newss < 0)) stop("negative values")
  return(newss)
}

data_fun <- function(x2,cxy,y2,cyz,z2, xT=100,yT=100,zT=100) {
  data.frame(name = rep(mymodel$states, 3),
                   time = rep(c(0.001,2000,3000), each = length(mymodel$states)),
                   value = c(c(100,0,0,100,0,0,100,0),  #initial values
                             rep(newsteadystate(x2,cxy,y2,cyz,z2, xT,yT,zT),2) #final values
                   ),
                   sigma = rep(c(0.01,0.1,0.1), each = length(mymodel$states)),
                   condition = "one", 
                   
                   stringsAsFactors = F) %>% as.datalist()
}

```

Turn it around: define the wanted steady states and fit the model to them in order to find pars.
```{r Fit model to generated data to find pars, eval=FALSE}
data <- data_fun(50,3,40,2,60)
obj <- normL2(data,(x*p_nosyndeg))
myfit <- mstrust(obj, pouter_0, cores = 3, fits = 9, studyname = "FindPars", resultPath = ".Findpars")
# pars <- myfit$argument %>% p_nosyndeg() %>% extract2(1) 
pars <- myfit %>% as.parframe() %>% as.parvec() %>% p_nosyndeg() %>% extract2(1)  

plot((x)(seq(0,1000,length.out = 50), pars))

```



## Explore the effect of the alpha when choosing elements to keep
This explores the effect of the alpha in the elements to keep - selection.

```{r Effect of alpha on r_kept, results='asis', echo=FALSE}
r_kept_fun_1 <-function(pars_opt = pars_opt_0,
                      perturbation_prediction = perturbation_prediction_0,
                      obs_fun = g0,
                      p_fun = p_pert,
                      pars = pars_0, 
                      alpha = 1) {
  
  # set pars_opt to zero
  pars_opt <- structure(rep(0, length(pars_opt)), names = names(pars_opt))
  
  r_0 <- R_fun(pars_opt = pars_opt,
               perturbation_prediction = perturbation_prediction,
               obs_fun = obs_fun,
               p_fun = p_fun,
               pars = pars) %>% local_response_matrix_eq10()
  
  r_alpha <- R_fun(pars_opt = pars_opt+alpha, #yields asymptotically the same results as only complexes without free species.
               perturbation_prediction = perturbation_prediction,
               obs_fun = obs_fun,
               p_fun = p_fun,
               pars = pars) %>% local_response_matrix_eq10()
  
  # Which elements are kept in the optimization process?
  signs <- (sign(r_0) - sign(r_alpha)) %>% as.logical() %>% matrix(nrow = nrow(r_0))
  abs_vals <- (abs(r_0) < 1e-3)
  
  keep <- (abs_vals | signs)
  
  return(cbind(keep, r_alpha))
}

wup <- lapply(10^(-4:8), function(a) {
  cat(" alpha = ", a, "\n")
  print(xtable(r_kept_fun_1(obs_fun = g0, alpha = a)), comment = F, floating = F)
  cat(" ")
  }) 
wup <- print(xtable(r_kept_fun_1(obs_fun = g1, alpha = 0)), comment = F, floating = F)
  cat(" ")


```




## Fit and analyze different conditions and perturbations

### Create lists for different settings
```{r Summary of pars and ic_list Cascade}
pars_perturbed_list <- vector("list", 6)
ic_list_list <- vector("list", 6)
pars_list <- vector("list", 6)
obs_fun_list <- vector("list", 6)
setting_description <- outer(
  paste0(c("xyz", "v1k4k7", "k1k31k61"), " perturbed, " ), 
  c("Small complex concentrations",
    "Medium small complex concentrations",
    "Medium complex concentrations",
    "Large complex concentrations"), 
    paste0)
```

## Setting 1: Small complex concentrationss
```{r Setting 1}
obs_fun_list <- lapply(1:6, function(i) g0)

pars_perturbed_list <- lapply(1:6, function(i) c("x1" = 0.5, "y1" = 0.5, "z1" = 0.5))

sdlog_list <- rep(c(0.01,0.1,0.2), 2) %>% as.list()

data <- data_fun(50,2,50,2,30)
obj <- normL2(data,(x*p_nosyndeg))
myfit <- mstrust(obj, pouter_0, cores = 3, fits = 3, studyname = "FindPars", resultPath = ".Findpars")
pars_list[[1]] <-pars_list[[2]] <-pars_list[[3]] <- pars <- (myfit %>% 
                                                               as.parframe() %>% 
                                                               as.parvec() %>% 
                                                               p_nosyndeg() %>% 
                                                               extract2(1))

data <- data_fun(35,30,35,30,30)
obj <- normL2(data,(x*p_nosyndeg))
myfit <- mstrust(obj, pouter_0, cores = 3, fits = 3, studyname = "FindPars", resultPath = ".Findpars")
pars_list[[4]] <-pars_list[[5]] <-pars_list[[6]] <- pars <- (myfit %>% 
                                                               as.parframe() %>% 
                                                               as.parvec() %>% 
                                                               p_nosyndeg() %>% 
                                                               extract2(1))

ic_list_list <- lapply(1:6, function(i) list(gainlf = c(1,0,5),
                                              gainuf = c(1,0,5),
                                              gainyf = c(1,0,5)))

ic_list <- ic_list_list[[1]]
p_ic <- p_ic_fun(reduce_ic_list(ic_list)[[1]])
plot((x*p_ic)(times = seq(0,1000, length.out = 50), pars))
```



# Fit the multiple conditions and save the fits to a file.
Run this only once before knitting and knit the document with the loaded dataset.
```{r Fit multiple conditions Cascade, eval=FALSE}
machine <- "tesla"
fit_job1<- runbg({
  myfits <- mclapply(seq_along(pars_list), function(i) {
    # cat("Setting ", i, " of ", length(pars_list), " \n")
    run_simulations(ic_list = ic_list_list[[i]],
                    nfits = 12,
                    cores = 12,
                    pars = pars_list[[i]],
                    pars_perturbed = pars_perturbed_list[[i]],
                    obs_fun = obs_fun_list[[i]]
                    )
    

  }, mc.cores = 2)
  names(myfits) <- paste0("Setting", seq_along(pars_list))
  myfits
}, machine = machine, filename = "fit_job1")
save.image()
```

```{r Get the fit Cascade, eval=FALSE, message=FALSE, results='hide'}
mytime <- 0
while(!fit_job1$check()) {
  Sys.sleep(5)
  mytime <- mytime + 5
}
beepr::beep(2)
multiple_fits <- fit_job1$get()
multiple_fits <- multiple_fits[[machine]]
# multiple_fits
save(multiple_fits, file = paste0(pathout,fit_name,".RData"))
fit_job1$purge()
```



## Analyze the fits
<!-- This is now to be run when pressing "render" -->
```{r Load the fits, eval=FALSE}
# Load the multiple fits
load(paste0(pathout,fit_name, ".RData"))
```

```{r Analyze Fits to knitr-Document Cascade, results='asis', out.width='45%', eval=FALSE}
lapply(seq_along(pars_list), function(setting) {
  
  cat("\\newpage
# Fit setting: ", setting, ": ", setting_description[setting], "
\n
### Standard pars of the following fits \n")
  print(xtable(as.matrix(pars_list[[setting]], nrow = 1), digits = 3), comment = F, floating = F)
    
  
  
  # multiple_fits <- lapply(seq_along(multiple_fits), function(j) {
  #   if(is.null(multiple_fits[[j]]$condition)) multiple_fits[[j]]$condition <- names(multiple_fits)[j]
  #   return(multiple_fits[[j]])
  # })
  output <- lapply(multiple_fits[[setting]], function(cond) {
    if(length(cond) == 1) return()
    cat("\\newpage
      # Condition: ",(cond$condition %>% str_split("_") %>% extract2(1) %>% paste(collapse = ", ") %>% str_replace_all("=", " = ")), "\n" )
    cat("\\textbf{Perturbed Parameters}: ", cond$pars_perturbed, "\n" )
    
    # Plot the result of the mstrust()
    print(plotValues(cond$all_fits) )
    print(plot(cond$prediction))
    
    cat(" \n Local response matrices before and after optimization. \n \n")
    cat(" Left is the local response matrix of free species, right is the matrix with complexes. \n")
    print(xtable(cbind(cond$r_0, rep(0, nrow(cond$r_0)), cond$r_alpha), digits = 5), comment = F, floating = F)
    cat(" ")
    print(xtable(cond$r_kept, digits = 5), comment = F, floating = F)
    cat(" ")
    print(xtable(cond$r_best_fit, digits = 5), comment = F, floating = F)
    
    cat("\n Best fit with reasonable parameter: \n")
    print(cond$best_fit %>% unclass %>%  matrix(.,nrow = 1, dimnames = list(NULL, names(.))) %>% xtable(digits = 3), comment = F, floating = F)
    
    cat("\n Steady state: \n")
    print(xtable(as.matrix(cond$steady_states[[1]])), comment = F, floating = F)
    
    cat("\n All fits: \n")
    print(xtable(cond$all_fits, digits = 4), comment = F, floating = F)
    return()
  })
})
```



# Noisy simulations

Run this only once before knitting and knit the document with the loaded dataset.
```{r Fit multiple conditions noisy, eval=FALSE}
machine <- "tesla"
fit_job1<- runbg({
  myfits <- mclapply(seq_along(pars_list), function(i) {
    # cat("Setting ", i, " of ", length(pars_list), " \n")
    run_simulations_with_noise(ic_list = ic_list_list[[i]],
                    n_samples = 500,
                    sdlog = sdlog_list[[i]],
                    cores = 24,
                    pars = pars_list[[i]],
                    pars_perturbed = pars_perturbed_list[[i]],
                    obs_fun = obs_fun_list[[i]]
                    )
    
  }, mc.cores = 1)
  names(myfits) <- paste0("Setting", seq_along(pars_list))
  myfits
}, machine = machine, filename = "fit_job1")
save.image()
```


```{r Get the fit noisy, eval=FALSE, message=FALSE, results='hide'}
mytime <- 0
while(capture.output(fit_job1$check())[[1]] == "Not ready!") {
  Sys.sleep(5)
  mytime <- mytime + 5
}
beepr::beep(2)
multiple_fits <- fit_job1$get()
multiple_fits <- multiple_fits[[machine]]
# multiple_fits
save(multiple_fits, file = paste0(pathout,fit_name,".RData"))
fit_job1$purge()
```



## Analyze the fits
<!-- This is now to be run when pressing "render" -->
```{r Load the fits noisy}
# Load the multiple fits
load(paste0(pathout,fit_name, ".RData"))
```

```{r Analyze Fits to knitr-Document noisy, results='asis', out.width='45%', warning=FALSE, message=FALSE}
library(tidyr)
library(dplyr)
wup <- lapply(seq_along(pars_list), function(setting) {
  
  cat("\\newpage
# Fit setting ", setting, ": ", setting_description[setting], "
      \n
### Standard pars of the following fits \n")
  print(xtable(as.matrix(pars_list[[setting]], nrow = 1), digits = 3), comment = F, floating = F)
  
  
  # multiple_fits <- lapply(seq_along(multiple_fits), function(j) {
  #   if(is.null(multiple_fits[[j]]$condition)) multiple_fits[[j]]$condition <- names(multiple_fits)[j]
  #   return(multiple_fits[[j]])
  # })
  output <- lapply(multiple_fits[[setting]], function(cond) {
    
cat("\\newpage \n
## Condition: ",(cond$condition %>% str_split("_") %>% extract2(1) %>% paste(collapse = ", ") %>% str_replace_all("=", " = ")), " \n" )
cat("\\textbf{Perturbed Parameters}: ", cond$pars_perturbed, "\n" )
cat("\\textbf{Standard deviation of Log-Normal distribution}: ", cond$sdlog, "\n" )

    
    # Plot the resulting local response matrices as histograms.
    # The failed simulations have to be removed first. They are recognizable by all elements equalling zero in r_ij
    failed <- cond$r_0$r11 == 0
    cat("\
        Number of failed fits: ", sum(failed) , "\n")
    cat("\n
        Distributions before and after optimization: 
        \n")
    if(sum(!failed) == 0) return()
    
    r_0 <- cond$r_0[!failed,] %>% tidyr::gather(key = element, value = value, everything())
    r_best_fit <- cond$r_best_fit[!failed,] %>% tidyr::gather(key = element, value = value, everything())
    
    # Join the two data.frames together. Since they have the exact same structure, I can just use cbind.
    r <- cbind(r_0, r_best_fit$value)
    names(r) <- c("element", "0", "optimized")
    r <- tidyr::gather_(r, key_col = "alpha", value_col = "value", gather_cols = c("0", "optimized"))
    
    
    print(ggplot(data = r, mapping = aes(x=alpha, y = value, fill = alpha)) + 
            geom_boxplot() + 
            facet_wrap(~element, scales = "free") + 
            theme_dMod() + 
       scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
         geom_hline(aes(yintercept = 0))
      )
      
    cat("\n
        Which elements were kept in the optimization procedure? 
        \n")
    
     print(ggplot(data = cond$r_kept[!failed,] %>% tidyr::gather(key = element, value = value, everything()),
                 mapping = aes(x=value)) + 
            geom_histogram(stat = "count") + 
            facet_wrap(~element, scales = "free_y") + 
            theme_dMod())
    
    # Plot the prediction
    # print(plot(cond$prediction))

    
    return()
  })
})

```














<!-- ------------------------------------------------------------------------------------------------- -->












<!-- ------------------------------------------------------------------------------------------------- -->







