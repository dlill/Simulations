---
title: "Cascade - x2z2 mass action feedback"
author: "Daniel Lill"
output:
  pdf_document:
    keep_tex: yes
---

# Load libraries and define some useful paths

```{r Libraries, results='hide', echo=FALSE, message=FALSE}
library(MRAr)
library(scales)
library(xtable)
path <- paste0(getwd(), "/")
pathout <- paste0(path, "Output/")
```

```{r Names for Fit storage of different initial Conditions}
fit_name <- "Cascade-x2z2-mass-action"
```


```{r Call render without overwriting any previous documents, echo=FALSE, eval=FALSE, message=FALSE}
mytime <- format(Sys.time(), "%Y%m%d-%H%M")

rmarkdown::render("Cascade.Rmd", output_file = paste0(pathout, fit_name, mytime, ".pdf"))
beepr::beep("~/Promotion/Software/rimshot.mp3")
```
# Cascade

## Setup Model 
This is the setup of the ODE model.

### Prediction function
odemodel writes a C-function, which is executed in x and xs.
x is a regular prediction function while xs only finds and returns the steady states.
If the odemodel has been calculated already, it can be loaded with "load".
```{r Prediction function Cascade, results='asis'}
modelpath <- paste0(path, "Models/Cascade/")
modelname   <- "Cascade"
mymodel     <- as.eqnlist(read.csv(paste0(modelpath, modelname, ".csv")))

# myodemodel <- odemodel(mymodel, modelname = paste0(modelname), deriv = T)
# save(myodemodel, file = paste0(modelpath, "odemodel",modelname, ".RData"))
load(paste0(modelpath, "odemodel",modelname, ".RData"))

# Prediction function
x <- Xs(odemodel = myodemodel)
# Prediction function for steady states
xs <- Xs_steady(myodemodel) # When computing steady states, set deriv = F
print(mymodel)
# mymodel %>% as.eqnvec() %>% print(pander = T)
```

### Modules, their observables and the observation function
Observation function which depends also on the optimization parameters. With their help, the complexes can smoothly be switched on in the observation.
```{r Observation function with Cx2z2 in x-module}
modules0 <- c("x2","y2", "z2")

obs0 <- c("x2+a_1*Cx2y1+a_3*Cx2z2",
          "y2+a_2*Cy2z1",
          "z2")
g <- g0 <- Y(as.eqnvec(structure(obs0, names = modules0)), mymodel, compile = TRUE, modelname = "obsfn0", attach.input = FALSE)
```

```{r Observation function with Cx2z2 in z-module}}
modules1 <- c("x2","y2", "z2")

obs1<- c("x2+a_1*Cx2y1",
         "y2+a_2*Cy2z1",
         "z2+a_3*Cx2z2")
g1 <- Y(as.eqnvec(structure(obs1, names = modules1)), mymodel, compile = TRUE, modelname = "obsfn1", attach.input = FALSE)
```

```{r Observation function with Cx2z2 in both modules}}
modules2 <- c("x2","y2", "z2")

obs2<- c("x2+a_1*Cx2y1+a_3*Cx2z2",
         "y2+a_2*Cy2z1",
         "z2+a_3*Cx2z2")
g2 <- Y(as.eqnvec(structure(obs2, names = modules2)), mymodel, compile = TRUE, modelname = "obsfn2", attach.input = FALSE)
```


### Inner parameters
Load all parameters and format them for further use.
```{r Parameters Cascade}

pars_raw <- read.csv(paste0(modelpath, "pars.csv"), header = FALSE)  # dynamical parameters
pars_raw <- structure(pars_raw$V2, names = as.character(pars_raw$V1))
ic_raw <- read.csv(paste0(modelpath, "IC.csv"), header = F)          # initial conditions
ic_raw <- structure(ic_raw$V2, names = as.character(ic_raw$V1))
# sort ics like they appear in x, so it can be used in stode()
vars_x <- attr(x, "parameters")[attr(x, "parameters") %in% names(ic_raw)]
ic_raw <- ic_raw[vars_x]

pars_inner_opt_0 <- setdiff(attr(g, "parameters"),names(c(pars_raw,ic_raw)))
pars_inner_opt_0 <- structure(rep(0, length(pars_inner_opt_0)), 
                              names = pars_inner_opt_0)

pars_inner_0 <- pars_inner <- c(ic_raw, pars_raw, pars_inner_opt_0)


# check if all parameters are assigned a value. Both lines should evaluate to the same number.
# x_pars <- unique(union((g) %>% attr("parameters"),(xs) %>% attr("parameters")))
# names(pars) %in% x_pars %>% sum()
# x_pars %in% names(pars) %>% sum()
```


### General log transformation and setting some pars to zero
It's better to do a logtransformation for all Fitting purposes and work with the log-Parameters.
The way to implement is this, is
log_pars %>% p_log %>% p_other %>% p_other_2 %>% ...
```{r}
# Logtrafo of all pars
logtrafo <- structure(paste0("exp( log", names(pars_inner_0), ")"), 
                             names = names(pars_inner_0))
# Kill Synthesis and degradation
syn_deg <- c(outer(c("ksyn", "kdeg"), c("x1","y1","z1"), FUN = paste0), 
              paste0("kdeg", c("x","y", "z"), "2"))
syn_deg <- structure(rep(0, length(syn_deg)), names = syn_deg)
logtrafo[names(syn_deg)] <- syn_deg
# Kill xz-feedback
xz_fb <- c("Cy2z1", "a_3", "k111", "k112", "k12")
xz_fb <- structure(rep(0, length(xz_fb)), names = xz_fb)
logtrafo[names(xz_fb)] <- xz_fb



p_log <- P(trafo = logtrafo,
           compile = TRUE,
           modelname = "p_log")
           

pars_0 <- pars <- structure(log(pars_inner_0+.Machine$double.eps), names = paste0("log", names(pars_inner_0))) 

pars_opt_0 <- pars_opt <- structure(log(pars_inner_opt_0+.Machine$double.eps), names = paste0("log", names(pars_inner_opt_0)))

pars_opt_0 <- pars_opt <- pars_opt_0[c("loga_1", "loga_2")]
# pars_0
# p_log(pars_0, deriv = F)
```


## Show the code
### Perturb modules
Now the module can be simulated to generate perturbation data.

### Parameter trafos for convenient perturbation data
Just to show the code...
Set up the perturbations
```{r  which pars are perturbed  Cascade, echo=FALSE}
# Which pars shall be perturbed?
pars_perturbed_0 <- pars_perturbed <- c("logx1" = log(0.8), "logy1" = log(0.8), "logz1" = log(0.8))
```


```{r define perturbation conditions Cascade, echo=FALSE}
p_pert <- p_pert_fun(pars_perturbed = pars_perturbed, pars = pars_0)
# (p_log*p_pert)(pars)
```

### Perturbation data generation and elements to keep
```{r Generate perturbation data, echo=FALSE}
perturbation_prediction_0 <-  (xs*p_log*p_pert)(times = c(0,Inf), pars = pars_0, deriv = F)
r_kept_0 <- r_kept_fun(obs_fun = g0)

```

----------------------------------------------------------------------------------------------------------------------------------
CONTINUE IMPLEMENTING THE P_LOG further down.
----------------------------------------------------------------------------------------------------------------------------------

```{r}
obj_alpha(pars_opt = pars_opt_0+39)
```



### Fitting
Just to show the code...
```{r Fit Cascade, eval=FALSE}
myfits <- mstrust(obj_alpha, center =  pars_opt_0+36, studyname = "Fits", cores = 3, fits = 3, sd = 1)
myfits %>% as.parframe() %>% plotValues()
best_fit <- myfits %>% as.parframe() %>% as.parvec()
```


## Find good parameter values by fitting parameters to chosen datapoints.
```{r Data generation for steady state fitting}
# Data generation
newsteadystate <- function(x2,cxy,y2,cyz,z2,cxz, xT=100,yT=100,zT=100) {
  newss <- c(
    xT-x2-cxy-cxz,
    x2,cxy,
    yT-cxy-y2-cyz,
    y2,cyz,
    zT-cyz-z2-cxz, 
    z2,
    cxz)
  if(any(newss < 0)) stop("negative values")
  return(newss)
}

data_fun <- function(x2,cxy,y2,cyz,z2,cxz, xT=100,yT=100,zT=100) {
  data.frame(name = rep(mymodel$states, 5),
             time = rep(c(0.001,1000,2000,3000,4000), 
                        each = length(mymodel$states)),
             value = c(c(100,0,0,100,0,0,100,0,0),  #initial values
                       rep(newsteadystate(x2,cxy,y2,cyz,z2,cxz, xT,yT,zT),4) #final values
             ),
             sigma = rep(c(0.01,0.1,0.001,0.0001,0.00001), 
                         each = length(mymodel$states)),
             condition = "C1",
             stringsAsFactors = F) %>% as.datalist()
}


```

Define the wanted steady states and fit the model to them in order to find pars.
```{r Fit model to generated data to find pars, eval=FALSE}
data <- data_fun(50,10,40,10,60,0)

p_log_fitting <- P(trafo = logtrafo,
                   condition = "C1",
                   compile = TRUE,
                   modelname = "p_log")

obj <- normL2(data,(x*p_log_fitting))
set.seed(1)
myfit <- mstrust(obj, pars_0, cores = 3, fits = 3, studyname = "FindPars", resultPath = ".Findpars")
# pars <- myfit$argument %>% p_nosyndeg() %>% extract2(1) 
pars <- myfit %>% as.parframe() %>% as.parvec()   

plot((x * p_log)(seq(0,1000,length.out = 50), pars))

```

# Benchmarking
```{r}
perturbation_prediction_0 <-  (xs*p_log*p_pert)(times = c(0,Inf), pars = pars, deriv = F)
r_kept_0 <- r_kept_fun(pars)



obj_alpha_no_derivs(pars_opt = pars_opt_0 +36)
obj_alpha(pars_opt = pars_opt_0 + 36)
```
# compare results of fits
```{r}

fits1 <- mstrust(obj_alpha, center =  pars_opt_0 + 36, samplefun = "runif", studyname = "Fits", cores = 4, fits = 8, max = 10, mypars = pars)
fits2 <- mclapply(1:8, function(i) optim(pars_opt_0+rnorm(2,36),obj_alpha_no_derivs, mypars = pars),mc.cores = 4)
fits3 <- mclapply(1:8, function(i) optim(pars_opt_0+rnorm(2,36),obj_alpha_no_derivs, mypars = pars, method = "BFGS"),mc.cores = 4)
fits5 <- mclapply(1:8, function(i) optim(pars_opt_0+rnorm(2,36),obj_alpha_no_derivs, mypars = pars, method = "L-BFGS-B"),mc.cores = 4)

```

```{r}
fits1 %>% as.parframe()
fits2 %>% sapply("[[", 1) 
fits3 %>% sapply("[[", 1) 
fits5 %>% sapply("[[", 1) 

fits1 %>% as.parframe()
fits2 %>% sapply("[[", 2) 
fits3 %>% sapply("[[", 2) 
fits5 %>% sapply("[[", 2) 
```


## runtimes
```{r, eval=FALSE}

optim1 <- rbenchmark::benchmark({mstrust(obj_alpha, center =  pars_opt_0+36, studyname = "Fits", cores = 1, fits = 1, mypars = pars)}, replications = 10)

optim2 <- rbenchmark::benchmark({
  optim(pars_opt_0+rnorm(2,36),
        obj_alpha_no_derivs, mypars = pars)}, replications = 10)

optim3 <- rbenchmark::benchmark({
  optim(pars_opt_0+rnorm(2,36),
        obj_alpha_no_derivs, method = "BFGS", mypars = pars)}, replications = 10)


# optim4 <- rbenchmark::benchmark({
  # optim(pars_opt_0+runif(3,0,10),
        # obj_alpha2, method = "SANN")}, replications = 10)

# optim4 <- 188

optim5 <- rbenchmark::benchmark({
  optim(pars_opt_0+rnorm(2,36),
        obj_alpha_no_derivs, method = "L-BFGS-B", mypars = pars)}, replications = 10)


obj_alpha_no_derivs(pars_opt = pars_opt_0 + 31)
```







## Explore the effect of the alpha when choosing elements to keep
This explores the effect of the alpha in the elements to keep - selection.

```{r Effect of alpha on r_kept, results='asis', echo=FALSE, eval=FALSE}
r_alpha <-function(pars_opt = pars_opt_0,
                      perturbation_prediction = perturbation_prediction_0,
                      obs_fun = g0,
                      p_fun = p_pert,
                      pars = pars_0) {
  # set pars_opt to zero
  sapply(pars_opt, function(i) {
    names(i) <- names(pars_opt_0)
    R_fun(pars_opt = i,
               perturbation_prediction = perturbation_prediction,
               obs_fun = obs_fun,
               p_fun = p_fun,
               pars = pars) %>% local_response_matrix_eq10() %>% unclass
    })
}

r_names <- paste0("r", outer(as.character(1:3),as.character(1:3), paste0))
mydf <- cbind(log10alpha = seq(-3,3,length.out = 50), 
              r_alpha(pars_opt = 10^seq(-3,3,length.out = 50)) %>% t %>% structure(. , dimnames = list(NULL,r_names))
              ) %>% as.data.frame(stringsAsFactors =  F)
mydf <- tidyr::gather_(mydf, key = "r_element", value = "Value", gather_cols = r_names)

myplot <- ggplot(mydf, mapping = aes(x = log10alpha, y = Value, color = r_element))+geom_line() + theme_dMod() + scale_color_dMod() + scale_x_continuous(breaks = scales::pretty_breaks()) 
# ggsave(filename = "Output/Prabakaran.r-values.pdf", plot = myplot)

```




# Create lists for different settings

### Initialize the setting lists
```{r Initialize lists}
pars_perturbed_list <- vector("list", 6)
ic_list_list <- vector("list", 6)
pars_list <- vector("list", 6)
obs_fun_list <- vector("list", 6)
setting_description <- outer(
  paste0("Cx2z2 added to ", c("x-module", "z-module", "both modules"), ", "), 
  c("Small complex concentrations",
    "Large complex concentrations"), 
    paste0)
```

## Many settings
```{r All settings}
obs_fun_list <- rep(list(g0,g1,g2),2)

pars_perturbed_list <- lapply(1:6, function(i) c("x1" = 0.5, "y1" = 0.5, "z1" = 0.5))

data <- data_fun(50,2,50,2,30,2)
obj <- normL2(data,(x*p_nosyndeg))
myfit <- mstrust(obj, pouter_0, cores = 3, fits = 3, studyname = "FindPars", resultPath = ".Findpars")
pars_list[[1]] <-pars_list[[2]] <-pars_list[[3]] <- pars <- (myfit %>% 
                                                               as.parframe() %>% 
                                                               as.parvec() %>% 
                                                               p_nosyndeg() %>% 
                                                               extract2(1))

data <- data_fun(30,30,30,30,30,30)
obj <- normL2(data,(x*p_nosyndeg))
myfit <- mstrust(obj, pouter_0, cores = 3, fits = 3, studyname = "FindPars", resultPath = ".Findpars")
pars_list[[4]] <-pars_list[[5]] <-pars_list[[6]] <- pars <- (myfit %>% 
                                                               as.parframe() %>% 
                                                               as.parvec() %>% 
                                                               p_nosyndeg() %>% 
                                                               extract2(1))

ic_list_list <- lapply(1:6, function(i) {
  list(k111 = signif(outer(pars_list[[i]]["k111"], exp(c(0,-2,-1,1,2)), "*"),2),
       k12 = signif(outer(pars_list[[i]]["k12"], c(0,exp(c(0,-2,-1,1,2))), "*"),2),
       gainlf = c(1,0,0.3,0.7,0.9))
})

ic_list <- ic_list_list[[1]]
p_ic <- p_ic_fun(reduce_ic_list(ic_list)[[1]])
# plot((x)(times = seq(0,2000, length.out = 50), pars_list[[1]])) + xkcd::theme_xkcd()
# plot((x)(times = seq(0,2000, length.out = 50), pars_list[[4]])) + xkcd::theme_xkcd()
# pars_list[[i]][names(reduce_ic_list(ic_list)[[2]])] <- reduce_ic_list(ic_list)[[2]]
```



# Simulations without noise

Run this only once before knitting and knit the document with the loaded dataset.
```{r Fit multiple conditions Cascade, eval=FALSE}
machine <- "localhost"
fit_job1<- runbg({
  myfits <- mclapply(seq_along(pars_list), function(i) {
    # cat("Setting ", i, " of ", length(pars_list), " \n")
    run_simulations(ic_list = ic_list_list[[i]],
                    nfits = 12,
                    cores = 3,
                    pars = pars_list[[i]],
                    pars_perturbed = pars_perturbed_list[[i]],
                    obs_fun = obs_fun_list[[i]]
                    )
    

  }, mc.cores = 1)
  names(myfits) <- paste0("Setting", seq_along(pars_list))
  myfits
}, machine = machine, filename = "fit_job1")
save.image()
```

```{r Get the fit Cascade, eval=FALSE, message=FALSE, results='hide'}
# mytime <- 0
while(!fit_job1$check()) {
  Sys.sleep(10)
  # mytime <- mytime + 5
}
beepr::beep(2)
multiple_fits <- fit_job1$get()
multiple_fits <- multiple_fits[[machine]]
# multiple_fits
save(list = c("multiple_fits", "pars_list"), file = paste0(pathout,fit_name,".RData"))
# fit_job1$purge()
```



## Rendering
<!-- This is now to be run when pressing "render" -->
```{r Load the fits}
# Load the multiple fits
load(paste0(pathout,fit_name, ".RData"))
```

```{r Analyze Fits to knitr-Document Cascade, results='asis', out.width='45%'}
lapply(seq_along(pars_list), function(setting) {
  
  cat("\\newpage
# Fit setting: ", setting, ": ", setting_description[setting], "
\n
### Standard pars of the following fits \n")
  print(xtable(as.matrix(pars_list[[setting]], nrow = 1), digits = 3), comment = F, floating = F)
    
  
  
  # multiple_fits <- lapply(seq_along(multiple_fits), function(j) {
  #   if(is.null(multiple_fits[[j]]$condition)) multiple_fits[[j]]$condition <- names(multiple_fits)[j]
  #   return(multiple_fits[[j]])
  # })
  output <- lapply(multiple_fits[[setting]], function(cond) {
    if(length(cond) == 1) return()
    cat("\\newpage
      # Condition: ",(cond$condition %>% str_split("_") %>% extract2(1) %>% paste(collapse = ", ") %>% str_replace_all("=", " = ")), "\n" )
    cat("\\textbf{Perturbed Parameters}: ", cond$pars_perturbed, "\n" )
    
    # Plot the result of the mstrust()
    print(plotValues(cond$all_fits) )
    print(plot(cond$prediction))
    
    cat(" \n Local response matrices before and after optimization. \n \n")
    cat(" Left is the local response matrix of free species, right is the matrix with complexes. \n")
    print(xtable(cbind(cond$r_0, rep(0, nrow(cond$r_0)), cond$r_alpha), digits = 5), comment = F, floating = F)
    cat(" ")
    print(xtable(cond$r_kept, digits = 5), comment = F, floating = F)
    cat(" ")
    print(xtable(cond$r_best_fit, digits = 5), comment = F, floating = F)
    
    cat("\n Best fit with reasonable parameter: \n")
    print(cond$best_fit %>% unclass %>%  matrix(.,nrow = 1, dimnames = list(NULL, names(.))) %>% xtable(digits = 3), comment = F, floating = F)
    
    cat("\n Steady state: \n")
    print(xtable(as.matrix(cond$steady_states[[1]])), comment = F, floating = F)
    
    cat("\n All fits: \n")
    print(xtable(cond$all_fits, digits = 4), comment = F, floating = F)
    return()
  })
})
```


## Explore simulations that behaved weirdly
This part is mainly about the simulations in Cascade-x2z2-mass-action20170418-1434. 
There, sometimes r_kept is not in accordance with the two matrices above. See page 40 of the pdf for example.
The problem however is that I don't have the parameters anymore, since some of them seem non-identifiable, so the pars that I get from fitting them to the steady state levels are different everytime I let the document run. 
This poses a problem, because I earlier didn't need to consider this and didn't save the parameters themselves.



# Noisy simulations

Run this only once before knitting and knit the document with the loaded dataset.
```{r Fit multiple conditions noisy, eval=FALSE}
machine <- "tesla"
fit_job1<- runbg({
  myfits <- mclapply(seq_along(pars_list), function(i) {
    # cat("Setting ", i, " of ", length(pars_list), " \n")
    run_simulations_with_noise(ic_list = ic_list_list[[i]],
                    n_samples = 500,
                    sdlog = sdlog_list[[i]],
                    cores = 24,
                    pars = pars_list[[i]],
                    pars_perturbed = pars_perturbed_list[[i]],
                    obs_fun = obs_fun_list[[i]]
                    )
    
  }, mc.cores = 1)
  names(myfits) <- paste0("Setting", seq_along(pars_list))
  myfits
}, machine = machine, filename = "fit_job1")
save.image()
```


```{r Get the fit noisy, eval=FALSE, message=FALSE, results='hide'}
mytime <- 0
while(capture.output(fit_job1$check())[[1]] == "Not ready!") {
  Sys.sleep(5)
  mytime <- mytime + 5
}
beepr::beep(2)
multiple_fits <- fit_job1$get()
multiple_fits <- multiple_fits[[machine]]
# multiple_fits
save(multiple_fits, file = paste0(pathout,fit_name,".RData"))
fit_job1$purge()
```



## Analyze the fits
<!-- This is now to be run when pressing "render" -->
```{r Load the fits noisy, eval=FALSE}
# Load the multiple fits
load(paste0(pathout,fit_name, ".RData"))
```

```{r Analyze Fits to knitr-Document noisy, results='asis', out.width='45%', warning=FALSE, message=FALSE, eval=FALSE}
library(tidyr)
library(dplyr)
wup <- lapply(seq_along(pars_list), function(setting) {
  
  cat("\\newpage")
cat("\n
# Fit setting ", setting, ": ", setting_description[setting])
cat("\n
### Standard pars of the following fits \n")
  print(xtable(as.matrix(pars_list[[setting]], nrow = 1), digits = 3), comment = F, floating = F)
  
  
  # multiple_fits <- lapply(seq_along(multiple_fits), function(j) {
  #   if(is.null(multiple_fits[[j]]$condition)) multiple_fits[[j]]$condition <- names(multiple_fits)[j]
  #   return(multiple_fits[[j]])
  # })
  output <- lapply(multiple_fits[[setting]], function(cond) {
    
cat("\\newpage \n
## Condition: ",(cond$condition %>% str_split("_") %>% extract2(1) %>% paste(collapse = ", ") %>% str_replace_all("=", " = ")), " \n" )
cat("\\textbf{Perturbed Parameters}: ", cond$pars_perturbed, "\n" )
cat("\\textbf{Standard deviation of Log-Normal distribution}: ", cond$sdlog, "\n" )

    
    # Plot the resulting local response matrices as histograms.
    # The failed simulations have to be removed first. They are recognizable by all elements equalling zero in r_ij
    failed <- cond$r_0$r11 == 0
    cat("\
        Number of failed fits: ", sum(failed) , "\n")
    cat("\n
        Distributions before and after optimization: 
        \n")
    if(sum(!failed) == 0) return()
    
    r_0 <- cond$r_0[!failed,] %>% tidyr::gather(key = element, value = value, everything())
    r_best_fit <- cond$r_best_fit[!failed,] %>% tidyr::gather(key = element, value = value, everything())
    
    # Join the two data.frames together. Since they have the exact same structure, I can just use cbind.
    r <- cbind(r_0, r_best_fit$value)
    names(r) <- c("element", "0", "optimized")
    r <- tidyr::gather_(r, key_col = "alpha", value_col = "value", gather_cols = c("0", "optimized"))
    
    
    print(ggplot(data = r, mapping = aes(x=alpha, y = value, fill = alpha)) + 
            geom_boxplot() + 
            facet_wrap(~element, scales = "free") + 
            theme_dMod() + 
       scale_y_continuous(breaks = scales::pretty_breaks(n = 3)) +
         geom_hline(aes(yintercept = 0))
      )
      
    cat("\n
        Which elements were kept in the optimization procedure? 
        \n")
    
     print(ggplot(data = cond$r_kept[!failed,] %>% tidyr::gather(key = element, value = value, everything()),
                 mapping = aes(x=value)) + 
            geom_histogram(stat = "count") + 
            facet_wrap(~element, scales = "free_y") + 
            theme_dMod())
    
    # Plot the prediction
    print(plot(cond$prediction))

    
    return()
  })
})

```














<!-- ------------------------------------------------------------------------------------------------- -->












<!-- ------------------------------------------------------------------------------------------------- -->







